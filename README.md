# ğŸ¤– OpsAI: Intelligent IT Support Automation

[![GitHub stars](https://img.shields.io/github/stars/pheonix-19/OpsAI.svg?style=social&label=Star)](https://github.com/pheonix-19/OpsAI)
[![GitHub forks](https://img.shields.io/github/forks/pheonix-19/OpsAI.svg?style=social&label=Fork)](https://github.com/pheonix-19/OpsAI/fork)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat&logo=fastapi)](https://fastapi.tiangolo.com/)

<!--
    Author: Ayush
    GitHub: https://github.com/pheonix-19
    Project: OpsAI - Intelligent IT Support Automation
    Copyright (c) 2025 Ayush. All rights reserved.
-->

> **Transform your IT helpdesk with AI-powered ticket triage and resolution suggestions**

OpsAI is an advanced AI system that revolutionizes IT support operations by automatically categorizing tickets, suggesting solutions, and routing requests to the right teams. Using cutting-edge vector embeddings and fine-tuned language models, it learns from historical data to provide instant, contextual support recommendations.

## ï¿½ **Live Screenshots**

**ğŸ–¥ï¸ Grafana Dashboard in Action:**
![Grafana OpsAI Dashboard](asset/grafana.png)
*Real-time monitoring dashboard showing API metrics, request rates, and system health*

**ğŸ“Š Prometheus Metrics Collection:**
![Prometheus Metrics](asset/promethius1.png)
*Prometheus collecting and displaying OpsAI application metrics*

**âš™ï¸ Prometheus Configuration & Targets:**
![Prometheus Targets](asset/promethius2.png)
*Prometheus monitoring targets and service discovery configuration*

## ï¿½ğŸ“‹ **Table of Contents**

- [ğŸ“¸ Live Screenshots](#-live-screenshots)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture--components)
- [ğŸ¯ What Problem Does OpsAI Solve?](#-what-problem-does-opsai-solve)
- [âœ¨ Core Features](#-core-features)
- [ğŸš€ Quick Demo](#-quick-demo)
- [ğŸ“‹ Prerequisites](#-prerequisites)
- [âš¡ Installation & Setup](#-installation--setup)
- [ğŸ® API Endpoints Reference](#-api-endpoints-reference)
- [ğŸ“Š Monitoring & Observability](#-monitoring--observability)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ” Security & Secrets Management](#-security--secrets-management)
- [ğŸ³ Docker & Deployment](#-docker--deployment)
- [ğŸ”— Enterprise Integrations](#-enterprise-integrations)
- [ğŸ§ª Testing & Development](#-testing--development)
- [ğŸš¨ Troubleshooting](#-troubleshooting)
- [ğŸš€ Quick Start Guide](#-quick-start-guide)
- [ğŸ“š Additional Resources](#-additional-resources)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License & Support](#-license--support)Intelligent IT Support Automation

<!--
    Author: Ayush
    GitHub: https://github.com/pheonix-19
    Project: OpsAI - Intelligent IT Support Automation
    Copyright (c) 2025 Ayush. All rights reserved.
-->

> **Transform your IT helpdesk with AI-powered ticket triage and resolution suggestions**

OpsAI is an ad## ğŸ” **Security & Secrets Management**anced AI system that revolutionizes IT support operations by automatically categorizing tickets, suggesting solutions, and routing requests to the right teams. Using cutting-edge vector embeddings and fine-tuned language models, it learns from historical data to provide instant, contextual support recommendations.

## ğŸ—ï¸ **System Architecture & Components**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ¤– OpsAI System Architecture                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           ğŸ‘¤ Users                     ğŸ”§ IT Teams                   ğŸ“Š Stakeholders
             â”‚                            â”‚                            â”‚
             â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               ğŸ”— Integration Layer                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ“‹ Jira      â”‚  ğŸ’¬ Slack Bot  â”‚ ğŸ« Freshdesk   â”‚     ğŸŒ Custom APIs             â”‚
â”‚   Webhooks     â”‚  Real-time     â”‚ Ticket Sync    â”‚     REST Endpoints             â”‚
â”‚   Automation   â”‚  Notifications â”‚ Customer Mgmt   â”‚     External Systems           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                            â”‚                            â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            ğŸš€ FastAPI Server (Port 8000)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ Endpoints:  /classify  |  /resolve  |  /feedback  |  /metrics  |  /docs        â”‚
â”‚                      â”‚           â”‚           â”‚           â”‚           â”‚              â”‚
â”‚                      â–¼           â–¼           â–¼           â–¼           â–¼              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ğŸ§  AI/ML Processing Core                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ” Vector Search   â”‚   ğŸ¤– Language Model   â”‚  ğŸ¯ Classification   â”‚ ğŸ”„ Learning  â”‚
â”‚                      â”‚                      â”‚                      â”‚              â”‚
â”‚  ğŸ“Š Embeddings:      â”‚  ğŸ§¬ Model:           â”‚ ğŸ·ï¸ Labels:           â”‚ ğŸ“ˆ Training: â”‚
â”‚  â€¢ sentence-trans    â”‚  â€¢ GPT-Neo-125M      â”‚ â€¢ auth, network      â”‚ â€¢ LoRA       â”‚
â”‚  â€¢ all-MiniLM-L6-v2  â”‚  â€¢ LoRA Fine-tuned   â”‚ â€¢ performance, mail  â”‚ â€¢ Adaptation â”‚
â”‚  â€¢ Vector Similarity â”‚  â€¢ Context-aware     â”‚ â€¢ Team Routing       â”‚ â€¢ Feedback   â”‚
â”‚                      â”‚                      â”‚                      â”‚              â”‚
â”‚  ğŸ—‚ï¸ FAISS Index:     â”‚  ğŸ’­ Generation:      â”‚ ğŸ¯ Mapping:          â”‚ ğŸ”„ Updates:  â”‚
â”‚  â€¢ Fast Search       â”‚  â€¢ Solution Suggest  â”‚ â€¢ IT Helpdesk        â”‚ â€¢ Continuous â”‚
â”‚  â€¢ Metadata Store    â”‚  â€¢ Context Tickets   â”‚ â€¢ Engineering        â”‚ â€¢ Improvementâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               ğŸ’¾ Data Storage Layer                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    ğŸ“ Raw Data       â”‚   âš™ï¸ Processed       â”‚   ğŸ—‚ï¸ Vector Index    â”‚ ğŸ“ Models    â”‚
â”‚                      â”‚                      â”‚                      â”‚              â”‚
â”‚  ğŸ“„ tickets.csv      â”‚  ğŸ“‹ Normalized:      â”‚  ğŸ” FAISS Database:  â”‚ ğŸ§¬ Weights:  â”‚
â”‚  ğŸ“„ tickets.json     â”‚  â€¢ ticket_0.json     â”‚  â€¢ ticket_index      â”‚ â€¢ LoRA       â”‚
â”‚  ğŸ“Š Historical Data  â”‚  â€¢ ticket_1.json     â”‚  â€¢ ticket_meta.pkl   â”‚ â€¢ Adapters   â”‚
â”‚  ğŸ”„ Continuous Feed  â”‚  â€¢ Clean Format      â”‚  â€¢ Fast Retrieval    â”‚ â€¢ Fine-tuned â”‚
â”‚                      â”‚  â€¢ Standardized      â”‚  â€¢ Similarity Search â”‚ â€¢ Checkpoint â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            ğŸ“Š Monitoring & Observability                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ˆ Prometheus       â”‚   ğŸ“Š Grafana         â”‚   ğŸš¨ Alerting        â”‚ ğŸ“ Logging   â”‚
â”‚  (Port 9090)         â”‚   (Port 3000)        â”‚                      â”‚              â”‚
â”‚                      â”‚                      â”‚                      â”‚              â”‚
â”‚  ğŸ“Š Metrics:         â”‚  ğŸ“‹ Dashboards:      â”‚  ğŸš¨ Alerts:          â”‚ ğŸ—‚ï¸ Logs:     â”‚
â”‚  â€¢ Request Count     â”‚  â€¢ Performance       â”‚  â€¢ High Error Rate   â”‚ â€¢ API Calls  â”‚
â”‚  â€¢ Response Time     â”‚  â€¢ Error Rates       â”‚  â€¢ Slow Response     â”‚ â€¢ Model Inf. â”‚
â”‚  â€¢ AI Performance   â”‚  â€¢ Business KPIs     â”‚  â€¢ System Down       â”‚ â€¢ Debug Info â”‚
â”‚  â€¢ System Health    â”‚  â€¢ Real-time Charts  â”‚  â€¢ Auto-notification â”‚ â€¢ Audit Trailâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ğŸ³ Infrastructure Layer                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ³ Docker Setup    â”‚   ğŸ Python Env     â”‚   ğŸ”¥ Hardware        â”‚ âš™ï¸ CI/CD     â”‚
â”‚                      â”‚                      â”‚                      â”‚              â”‚
â”‚  ğŸ“‹ Services:        â”‚  ğŸ“¦ Dependencies:    â”‚  ğŸ’» Requirements:    â”‚ ğŸ”„ Pipeline: â”‚
â”‚  â€¢ API Container     â”‚  â€¢ transformers      â”‚  â€¢ Python 3.11+     â”‚ â€¢ GitHub     â”‚
â”‚  â€¢ Prometheus        â”‚  â€¢ fastapi           â”‚  â€¢ 8GB+ RAM          â”‚ â€¢ Actions    â”‚
â”‚  â€¢ Grafana           â”‚  â€¢ torch             â”‚  â€¢ CUDA GPU (opt)    â”‚ â€¢ Testing    â”‚
â”‚  â€¢ Auto-scaling      â”‚  â€¢ faiss-cpu         â”‚  â€¢ 4GB Disk          â”‚ â€¢ Deploy     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ğŸ“ˆ Data Flow Direction                                 â”‚
â”‚                                                                                     â”‚
â”‚  Tickets â†’ Integration â†’ API â†’ AI Processing â†’ Data Storage â†’ Monitoring            â”‚
â”‚     â†‘                                          â†“                     â†“             â”‚
â”‚  Feedback â†â”€â”€ Solutions â†â”€â”€ Intelligence â†â”€â”€ Training â†â”€â”€ Analytics â†â”€â”€ Metrics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ **What Problem Does OpsAI Solve?**

### **Before OpsAI (Traditional IT Support):**
```
User reports issue â†’ Manual ticket review â†’ Search past solutions â†’ Assign to team â†’ Resolution
â±ï¸ Hours/Days        ğŸ’° High cost        ğŸ” Time-intensive   ğŸ‘¥ Manual routing
```

### **With OpsAI (AI-Powered Support):**
```
User reports issue â†’ AI instant analysis â†’ Auto-suggested solution â†’ Smart team routing â†’ Fast resolution
âš¡ Seconds           ğŸ’° Cost efficient   ğŸ§  AI-powered      ğŸ¯ Accurate routing
```

## âœ¨ **Core Features**

| Feature | Description | Business Impact |
|---------|-------------|-----------------|
| ğŸ¯ **Smart Classification** | AI categorizes tickets by type (auth, network, performance) | Automatic team routing |
| ğŸ§  **Resolution Suggestions** | Generates solutions based on similar past cases | Faster problem solving |
| ğŸ” **Semantic Search** | Finds relevant tickets using AI understanding, not just keywords | Better context matching |
| ğŸ“Š **Real-time Monitoring** | Prometheus metrics + Grafana dashboards | System health visibility |
| ğŸ”— **Enterprise Integration** | Connects with Jira, Slack, Freshdesk | Seamless workflow integration |
| ğŸ“ **Continuous Learning** | LoRA fine-tuning adapts to your organization | Improving accuracy over time |

## ğŸš€ **Quick Demo**

### **Example 1: Ticket Classification**
```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{"text": "Cannot access email, getting authentication errors"}'
```
**Response:**
```json
{
  "tags": ["auth", "mail", "user"],
  "teams": ["IT Helpdesk"]
}
```

### **Example 2: AI Resolution Suggestion**
```bash
curl -X POST "http://localhost:8000/resolve" \
  -H "Content-Type: application/json" \
  -d '{"text": "Database connection timeout in production"}'
```
**Response:**
```json
{
  "suggestion": "Check database connection pool settings and increase timeout values...",
  "context_tickets": [{"title": "Similar DB issue", "resolution": "..."}]
}
```

## ğŸ“‹ **Prerequisites**

- **Python 3.11+** (tested with 3.12.3)
- **8GB+ RAM** (for AI model inference)
- **Docker & Docker Compose** (for full stack deployment)
- **CUDA-compatible GPU** (optional, for faster inference)
- **4GB disk space** (for models and vector index)

## âš¡ **Installation & Setup**

### **Method 1: Local Development (Recommended for Testing)**

1. **Clone and Setup Environment:**
```bash
git clone https://github.com/pheonix-19/OpsAI.git
cd OpsAI

# Create virtual environment
python3 -m venv env
source env/bin/activate  # Linux/macOS
# env\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
pip install -e .
```

2. **Process Sample Data and Build AI Index:**
```bash
# Process the included sample tickets
PYTHONPATH=. python -m src.ingestion.ingest data/raw data/processed

# Build vector embeddings index for semantic search
PYTHONPATH=. python -m src.embeddings.build_index --input-dir data/processed --output-dir data/index
```

3. **Start the API Server:**
```bash
PYTHONPATH=. uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

4. **Access the System:**
- **API Documentation**: http://localhost:8000/docs
- **Metrics Endpoint**: http://localhost:8000/metrics

### **Method 2: Full Production Stack (Docker)**

```bash
# Start complete monitoring stack
docker-compose up --build

# Access services:
# - OpsAI API: http://localhost:8000
# - Prometheus: http://localhost:9090  
# - Grafana: http://localhost:3000 (admin/admin)
```

## ğŸ® **API Endpoints Reference**

| Endpoint | Method | Purpose | Example Use Case |
|----------|--------|---------|------------------|
| `/` | GET | Health check | Service monitoring |
| `/classify` | POST | Categorize tickets | Auto-route to teams |
| `/resolve` | POST | Get AI suggestions | Provide solutions |
| `/feedback` | POST | Submit user ratings | Improve AI accuracy |
| `/metrics` | GET | Prometheus metrics | System monitoring |

### **Detailed API Usage:**

#### **ğŸ¯ Classify Tickets**
```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Server not responding to ping requests",
    "top_k": 3
  }'
```

#### **ğŸ§  Get AI Resolutions**
```bash
curl -X POST "http://localhost:8000/resolve" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Application crashes when uploading large files", 
    "top_k": 5
  }'
```

#### **ğŸ“ Submit Feedback**
```bash
curl -X POST "http://localhost:8000/feedback" \
  -H "Content-Type: application/json" \
  -d '{
    "ticket": {"title": "Login issue", "description": "Cannot access system"},
    "suggestion": "Reset password and clear browser cache",
    "rating": 5,
    "comment": "Perfect solution, worked immediately!"
  }'
```

## ğŸ“Š **Monitoring & Observability**

### **ğŸ” Prometheus Metrics**
OpsAI automatically tracks comprehensive performance metrics:

```bash
# View current metrics
curl http://localhost:8000/metrics | grep opsai

# Example metrics output:
opsai_requests_total{endpoint="/classify",method="POST"} 5.0
opsai_request_latency_seconds_sum{endpoint="/resolve"} 2.28
```

**Key Metrics Tracked:**
- **Request Volume**: API calls per endpoint per second
- **Response Times**: Latency percentiles (50th, 90th, 99th)
- **Error Rates**: Failed requests and status codes
- **AI Performance**: Model inference times
- **Business KPIs**: Total tickets processed

### **ğŸ“ˆ Grafana Dashboards** âœ… **CONFIGURED & WORKING**

**âœ… Active Dashboards:**
1. **OpsAI Monitoring Dashboard** - Real-time API metrics
2. **Prometheus 2.0 Stats** - System performance monitoring  
3. **Prometheus Stats** - Infrastructure metrics

**ğŸ“Š Access:** http://localhost:3000 (admin/admin)

**Dashboard Features:**
- ğŸ“Š **Total API Requests**: Live request tracking
- â±ï¸ **Request Rate**: Real-time requests per minute
- ğŸš¨ **HTTP Status Codes**: Success vs Error monitoring
- ğŸ“ˆ **Endpoint Breakdown**: Usage analytics by endpoint
- ğŸ¥§ **Visual Analytics**: Interactive charts and tables

### **ï¿½ Live Screenshots**

**ğŸ–¥ï¸ Grafana Dashboard in Action:**
![Grafana OpsAI Dashboard](asset/grafana.png)
*Real-time monitoring dashboard showing API metrics, request rates, and system health*

**ğŸ“Š Prometheus Metrics Collection:**
![Prometheus Metrics](asset/promethius1.png)
*Prometheus collecting and displaying OpsAI application metrics*

**âš™ï¸ Prometheus Configuration & Targets:**
![Prometheus Targets](asset/promethius2.png)
*Prometheus monitoring targets and service discovery configuration*

### **ï¿½ğŸ” Prometheus Query Examples**
Essential queries for monitoring (see `PROMETHEUS_QUERIES.md` for complete reference):

```promql
# Basic metrics
sum(opsai_requests_total) by (endpoint)          # Total requests by endpoint
rate(opsai_requests_total[5m])                   # Request rate per second

# Performance monitoring  
avg(opsai_request_latency_seconds) by (endpoint) # Average response time
histogram_quantile(0.95, rate(opsai_request_latency_seconds_bucket[5m])) # 95th percentile
```

## ğŸ“ **Project Structure**
```
opsai/
â”œâ”€â”€ src/                     # Core application code
â”‚   â”œâ”€â”€ api/                 # FastAPI endpoints
â”‚   â”œâ”€â”€ embeddings/          # Vector search & FAISS
â”‚   â”œâ”€â”€ ingestion/           # Data processing 
â”‚   â”œâ”€â”€ integrations/        # External APIs (Jira, Slack)
â”‚   â”œâ”€â”€ model_training/      # AI model fine-tuning
â”‚   â””â”€â”€ monitoring/          # Prometheus metrics
â”œâ”€â”€ data/                    # Training data & indexes
â”œâ”€â”€ models/                  # LoRA adapters & weights
â”œâ”€â”€ tests/                   # Test suite
â””â”€â”€ infra/                   # Docker & monitoring configs
```

## ï¿½ **Security & Secrets Management**

### **ğŸš¨ Important: Managing Secrets in Public Repositories**

âš ï¸ **NEVER commit actual secrets to your repository!** This guide shows you how to securely manage environment variables and API keys for both local development and CI/CD.

#### **ğŸ“‹ Required vs Optional Credentials**

| **Credential** | **Required For** | **Default Behavior** |
|---------------|------------------|---------------------|
| `DATABASE_URL` | Database connection | âœ… Defaults to local SQLite |
| `OPENAI_API_KEY` | OpenAI features | âš ï¸ Optional - features disabled if missing |
| `HUGGINGFACE_API_TOKEN` | Model downloads | âš ï¸ Optional - uses cached/local models |
| `JIRA_API_TOKEN` | JIRA integration | âš ï¸ Only if using JIRA |
| `SLACK_BOT_TOKEN` | Slack bot | âš ï¸ Only if using Slack |
| `FRESHDESK_API_KEY` | Freshdesk integration | âš ï¸ Only if using Freshdesk |
| `DOCKERHUB_USER/TOKEN` | CI/CD deployment | âš ï¸ Only for Docker Hub publishing |

#### **ğŸ›¡ï¸ Local Development Setup**

1. **Copy environment template:**
```bash
cp .env.example .env
```

2. **Edit `.env` with your actual values (NEVER commit this file):**
```bash
# Required only if using specific integrations
JIRA_URL="https://your-company.atlassian.net"
JIRA_USER="your-email@company.com"
JIRA_API_TOKEN="your_new_jira_token_here"

SLACK_BOT_TOKEN="xoxb-your-slack-bot-token-here"
SLACK_APP_TOKEN="xapp-your-slack-app-token-here"

# Optional - for enhanced AI features
OPENAI_API_KEY="sk-your-openai-key-here"
HUGGINGFACE_API_TOKEN="hf_your-token-here"
```

3. **The `.env` file is automatically ignored by git** (included in `.gitignore`)

#### **ğŸ”‘ GitHub Secrets for CI/CD**

For GitHub Actions to work with your secrets:

1. **Go to GitHub Repository Settings**
2. **Navigate to:** Settings â†’ Secrets and variables â†’ Actions
3. **Add these secrets** (only the ones you need):

```
# Docker deployment (required for CI/CD)
DOCKERHUB_USER=your_dockerhub_username
DOCKERHUB_TOKEN=your_dockerhub_access_token

# Integration secrets (optional)
JIRA_API_TOKEN=your_jira_token
SLACK_BOT_TOKEN=your_slack_token
FRESHDESK_API_KEY=your_freshdesk_key
```

#### **âœ… Security Best Practices Implemented**

- âœ… **No secrets in source code** - All credentials from environment variables
- âœ… **Secure config validation** - `src/config.py` handles missing secrets gracefully
- âœ… **Environment isolation** - Production vs development detection
- âœ… **CI/CD ready** - GitHub Actions configured with proper secret injection
- âœ… **Optional integrations** - Core functionality works without external APIs

#### **ğŸ”§ Security Configuration Files**

**Key files for security:**
- `.env.example` - Template with placeholder values (safe to commit)
- `src/config.py` - Secure configuration management 
- `.gitignore` - Ensures `.env` files are never committed
- `SECURITY.md` - Complete security guidelines

### **ğŸš¨ Token Security Checklist**

- [ ] All real tokens removed from version control
- [ ] `.env` file exists locally with actual values
- [ ] GitHub secrets configured for CI/CD
- [ ] Old/exposed tokens revoked and regenerated
- [ ] Team members trained on security practices

## ğŸ³ **Docker & Deployment**

### **ğŸ› ï¸ Fixed Docker Build Issues**

**Common Docker problems and solutions implemented:**

#### **âŒ Problem: Package Version Conflicts**
```
ERROR: Could not find a version that satisfies the requirement tokenizers==0.21.2
ERROR: No matching distribution found for SQLAlchemy==2.0.23
```

#### **âœ… Solution: Flexible Version Ranges**
Updated `requirements.txt` to use compatible version ranges instead of pinned versions:

```python
# Before (problematic)
tokenizers==0.21.2
SQLAlchemy==2.0.23

# After (working)
tokenizers>=0.13.0,<1.0.0
SQLAlchemy>=1.4.0,<3.0.0
```

#### **âŒ Problem: Network Timeouts During Build**
```
pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool: Read timed out
```

#### **âœ… Solution: Enhanced Dockerfile**
```dockerfile
# Install with increased timeout and retries
RUN pip install --no-cache-dir \
    --timeout 1000 \
    --retries 5 \
    --default-timeout=1000 \
    -r requirements.txt
```

### **ğŸš€ Deployment Options**

#### **Option 1: Quick Development Setup**
```bash
# Minimal setup for development
cp requirements-minimal.txt requirements.txt
docker-compose up --build
```

#### **Option 2: Full Production Stack**
```bash
# Complete setup with all features
docker-compose up --build
```

#### **Option 3: Retry Script (Handles Network Issues)**
```bash
# Automated retry with fallback to minimal setup
./docker-build.sh
```

### **ğŸ“¦ Docker Services Overview**

| **Service** | **Port** | **Purpose** | **Health Check** |
|-------------|----------|-------------|------------------|
| `opsai-api` | 8000 | Main application | `curl localhost:8000/` |
| `prometheus` | 9090 | Metrics collection | `curl localhost:9090/-/healthy` |
| `grafana` | 3000 | Monitoring dashboards | `curl localhost:3000/api/health` |

### **ğŸ”§ Docker Troubleshooting**

**Check service status:**
```bash
docker-compose ps
docker-compose logs api
```

**Restart specific service:**
```bash
docker-compose restart api
docker-compose restart prometheus
```

**Clean rebuild:**
```bash
docker-compose down
docker system prune -f
docker-compose up --build --no-cache
```

## ğŸ“Š **Monitoring & Metrics - Complete Setup Guide**

### **ğŸ¯ Prometheus Configuration**

**âœ… Working Prometheus Setup:**

```yaml
# infra/prometheus/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'      # Self-monitoring
    static_configs:
      - targets: ['localhost:9090']
    
  - job_name: 'opsai_api'       # Application monitoring
    static_configs:
      - targets: ['api:8000']
```

### **ğŸ“ˆ Grafana Dashboard Setup**

**âœ… Auto-configured Grafana features:**

1. **Data Source**: Prometheus auto-configured at `http://prometheus:9090`
2. **Dashboards**: Pre-built OpsAI monitoring dashboard
3. **Provisioning**: Automatic setup via configuration files

**Access:** http://localhost:3000 (admin/admin)

### **ğŸ“Š Available Metrics & Queries**

#### **ğŸš€ OpsAI Application Metrics**

**âœ… Confirmed Working Queries:**

```promql
# Instant metrics (always show data)
opsai_requests_total                              # Total API requests
process_resident_memory_bytes{job="opsai_api"}   # Memory usage
time() - process_start_time_seconds{job="opsai_api"}  # Uptime
up{job="opsai_api"}                              # Service availability
python_gc_objects_collected_total{job="opsai_api"}    # Python metrics

# Aggregated metrics
sum by (endpoint) (opsai_requests_total)         # Requests by endpoint  
sum by (http_status) (opsai_requests_total)      # Requests by status code
```

#### **ğŸ“ˆ Rate-based Metrics (Need Traffic)**

```promql
# Generate traffic first: ./generate-traffic.sh
rate(opsai_requests_total[5m])                   # Request rate
rate(process_cpu_seconds_total{job="opsai_api"}[5m]) * 100  # CPU usage
histogram_quantile(0.95, rate(opsai_request_latency_seconds_bucket[5m]))  # 95th percentile latency
```

### **ğŸ” Testing Metrics**

**Generate test traffic:**
```bash
# Continuous traffic generation
./generate-traffic.sh

# Or manual testing
for i in {1..20}; do 
  curl -s http://localhost:8000/ > /dev/null
  curl -s http://localhost:8000/docs > /dev/null
  sleep 1
done
```

**Verify metrics in Prometheus:**
```bash
# Check if metrics are being collected
curl -s "http://localhost:9090/api/v1/query?query=opsai_requests_total" | jq '.data.result | length'

# Test specific queries
curl -s "http://localhost:9090/api/v1/query?query=up{job=\"opsai_api\"}"
```

### **ğŸ“‹ Grafana Dashboard Features**

**Working dashboard panels:**
- ğŸ“Š **Total API Requests**: Real-time request count
- â±ï¸ **Request Rate**: Requests per minute over time
- ğŸ¥§ **HTTP Status Codes**: Success vs error breakdown  
- ğŸ“ˆ **Request Latency**: Response time percentiles
- ğŸ’¾ **Memory Usage**: RAM consumption tracking
- â° **Service Uptime**: Time since last restart

### **ğŸš¨ Monitoring Troubleshooting**

**If Grafana shows "No Data":**

1. **Check Prometheus targets:**
   ```bash
   curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'
   ```

2. **Verify data source in Grafana:**
   - URL should be: `http://prometheus:9090`
   - Click "Save & Test" - should show green "Data source is working"

3. **Test simple queries in Grafana:**
   - Start with: `opsai_requests_total`
   - Set time range to "Last 15 minutes"
   - Enable auto-refresh (5s)

4. **Generate traffic if needed:**
   ```bash
   ./generate-traffic.sh
   ```

### **ğŸ“ˆ Custom Dashboard Creation**

**Manual dashboard setup:**
1. Go to Grafana â†’ "+" â†’ Dashboard â†’ Add new panel
2. Enter query: `opsai_requests_total`
3. Set visualization type (Time series, Stat, etc.)
4. Configure time range and refresh interval
5. Save dashboard

### **ğŸ”§ Monitoring Best Practices**

- âœ… **Start simple**: Use instant metrics first (`opsai_requests_total`)
- âœ… **Generate traffic**: Use `./generate-traffic.sh` for rate metrics
- âœ… **Check time ranges**: Use "Last 15 minutes" for recent data
- âœ… **Verify targets**: Ensure Prometheus is scraping successfully
- âœ… **Test queries**: Use Prometheus UI to validate queries before Grafana

## ğŸ“š **Step-by-Step Setup Walkthrough**

### **ğŸš€ Complete Setup from Scratch**

#### **1. Repository Setup**
```bash
git clone https://github.com/pheonix-19/OpsAI.git
cd OpsAI
```

#### **2. Security Configuration**
```bash
# Copy environment template
cp .env.example .env

# Edit .env with your actual credentials (optional)
nano .env

# Verify .env is in .gitignore
grep -q "^\.env$" .gitignore && echo "âœ… .env properly ignored"
```

#### **3. Docker Build (with retry logic)**
```bash
# Method 1: Automated retry script
chmod +x docker-build.sh
./docker-build.sh

# Method 2: Manual build
docker-compose up --build

# Method 3: Minimal build (if having issues)
cp requirements-minimal.txt requirements.txt
docker-compose up --build
```

#### **4. Verify Services**
```bash
# Check all services are running
docker-compose ps

# Test API
curl http://localhost:8000/

# Test metrics endpoint
curl http://localhost:8000/metrics | head -10

# Check Prometheus targets
curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[].health'
```

#### **5. Setup Monitoring**
```bash
# Generate test traffic
./generate-traffic.sh &

# Open Grafana (admin/admin)
open http://localhost:3000

# Open Prometheus
open http://localhost:9090
```

#### **6. Test AI Features**
```bash
# Test classification
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{"text": "Cannot login to email account"}'

# Test resolution suggestions  
curl -X POST "http://localhost:8000/resolve" \
  -H "Content-Type: application/json" \
  -d '{"text": "Database connection timeout error"}'
```

### **ğŸ”§ CI/CD Setup**

#### **GitHub Actions Configuration**

Your repository includes automated CI/CD with these workflows:

**`.github/workflows/ci.yml`** - Tests and builds on every push:
```yaml
# Automatically runs:
- Python linting with flake8
- Test suite with pytest  
- Docker image build
- Deployment to Docker Hub (if secrets configured)
```

**`.github/workflows/retrain.yml`** - Scheduled model retraining:
```yaml
# Runs weekly to:
- Retrain AI models with new data
- Update LoRA adapters
- Upload new model artifacts
```

#### **Required GitHub Secrets for CI/CD**

**Minimal setup (for basic CI/CD):**
```
DOCKERHUB_USER=your_dockerhub_username
DOCKERHUB_TOKEN=your_dockerhub_access_token
```

**Full setup (for all integrations):**
```
JIRA_API_TOKEN=your_jira_token
SLACK_BOT_TOKEN=your_slack_token  
FRESHDESK_API_KEY=your_freshdesk_key
```

### **ğŸ“ Configuration Files Reference**

| **File** | **Purpose** | **When to Edit** |
|----------|-------------|------------------|
| `.env.example` | Template for environment variables | Never (contains placeholders) |
| `.env` | Your actual secrets (not in git) | Add your real credentials |
| `src/config.py` | Configuration management | Customize app settings |
| `requirements.txt` | Python dependencies | Add new packages |
| `docker-compose.yml` | Service orchestration | Modify ports/volumes |
| `infra/prometheus/prometheus.yml` | Metrics collection | Add monitoring targets |

### **ğŸ¯ Quick Validation Checklist**

- [ ] Services start: `docker-compose ps` shows all running
- [ ] API responds: `curl http://localhost:8000/` returns JSON
- [ ] Metrics work: `curl http://localhost:8000/metrics` shows data
- [ ] Prometheus scraping: Targets page shows "UP" status
- [ ] Grafana connected: Data source test succeeds
- [ ] Dashboards show data: Generate traffic and verify graphs
- [ ] AI features work: Classification and resolution endpoints respond
- [ ] Security configured: No real secrets in git, `.env` properly ignored

This comprehensive setup ensures your OpsAI deployment is secure, monitored, and production-ready! ğŸ‰

## ğŸ”— **Enterprise Integrations**

### **ğŸ“‹ Jira Integration**
```bash
# Environment variables for Jira
JIRA_URL=https://your-domain.atlassian.net
JIRA_USER=your-email@company.com
JIRA_API_TOKEN=your-api-token

# Auto-process tickets from Jira webhooks
# POST /jira/webhook - Receives ticket updates
```

### **ğŸ’¬ Slack Bot Integration**
```bash
# Slack bot configuration
SLACK_BOT_TOKEN=xoxb-your-bot-token
SLACK_APP_TOKEN=xapp-your-app-token

# Start the Slack bot
python src/integrations/slack_bot.py
```

## ğŸ§ª **Testing & Development**

### **Run Test Suite:**
```bash
# Run all tests
pytest

# Run specific modules
pytest tests/test_api.py        # API endpoint tests
pytest tests/test_embeddings.py # Vector search tests
pytest tests/test_ingestion.py  # Data processing tests
```

### **Development Workflow:**
```bash
# Hot reload during development
uvicorn src.api.main:app --reload --port 8000

# Process new training data
python src/ingestion/ingest.py --input data/raw/new_tickets.csv

# Rebuild search index
python src/embeddings/build_index.py --input-dir data/processed --output-dir data/index
```

## ğŸš¨ **Troubleshooting**

### **Common Issues & Solutions**

**ğŸ”§ Device Mismatch Error:**
```
RuntimeError: Expected all tensors to be on the same device
```
**Solution:** âœ… Fixed in latest version - tensors automatically moved to correct device

**ğŸ”§ Import Errors:**
```
ImportError: attempted relative import with no known parent package
```
**Solution:** Use `PYTHONPATH=. python -m src.module.script`

**ğŸ”§ Port Already in Use:**
```
OSError: [Errno 98] Address already in use
```
**Solution:** Use different port: `--port 8001` or kill existing process

### **Debugging Commands**
```bash
# Check API health
curl http://localhost:8000/

# View current metrics
curl http://localhost:8000/metrics | grep opsai

# Check Docker services
docker-compose ps
```

## ğŸš€ **Quick Start Guide**

**1. Test Basic Classification:**
```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{"text": "Password reset needed for user account"}'
```

**2. Get AI-Powered Solutions:**
```bash
curl -X POST "http://localhost:8000/resolve" \
  -H "Content-Type: application/json" \
  -d '{"text": "Email server connection timeout"}'
```

**3. Provide Feedback for Learning:**
```bash
curl -X POST "http://localhost:8000/feedback" \
  -H "Content-Type: application/json" \
  -d '{
    "ticket": {"title": "Login issue"},
    "suggestion": "Reset password", 
    "rating": 5,
    "comment": "Perfect solution!"
  }'
```

## ğŸ“š **Additional Resources**

### **ğŸ”— Useful Links**
- **ğŸ“– API Documentation**: http://localhost:8000/docs (when running)
- **ğŸ“Š Monitoring**: http://localhost:3000 (Grafana dashboards)  
- **ğŸ” Metrics**: http://localhost:9090 (Prometheus)
- **ğŸ“‹ Query Reference**: See `PROMETHEUS_QUERIES.md` for complete monitoring guide
- **ğŸ› Issues**: https://github.com/pheonix-19/OpsAI/issues
- **ğŸ’¬ Discussions**: https://github.com/pheonix-19/OpsAI/discussions

### **ğŸ“– Technical Stack**
- **Vector Embeddings**: `sentence-transformers/all-MiniLM-L6-v2`
- **Language Model**: `EleutherAI/gpt-neo-125M` with LoRA fine-tuning
- **Search Index**: FAISS (Facebook AI Similarity Search)
- **Monitoring**: Prometheus + Grafana stack
- **API Framework**: FastAPI with automatic OpenAPI docs

## ğŸ¤ **Contributing**

We welcome contributions! Here's how to get started:

### **ğŸ› ï¸ Development Setup**
```bash
# Fork the repository
git clone https://github.com/your-username/OpsAI.git
cd OpsAI

# Create feature branch
git checkout -b feature/amazing-improvement

# Make changes and test
pytest
pre-commit run --all-files

# Submit pull request
git push origin feature/amazing-improvement
```

### **ğŸ¯ Contribution Areas**
- ğŸ› **Bug Fixes**: Fix issues and improve stability
- âœ¨ **New Features**: Add integrations, UI improvements, ML enhancements
- ğŸ“š **Documentation**: Improve guides, examples, and API docs
- ğŸ§ª **Testing**: Add test coverage and performance benchmarks

## ğŸ“„ **License & Support**

### **ğŸ“œ License**
This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### **ğŸ†˜ Getting Help**

**For Questions:**
1. ğŸ“– Check this README and API documentation first
2. ğŸ” Search existing [GitHub issues](https://github.com/pheonix-19/OpsAI/issues)
3. ğŸ’¬ Start a [GitHub discussion](https://github.com/pheonix-19/OpsAI/discussions)
4. ğŸ› Create a new issue with detailed information

**For Bugs:**
Include in your issue:
- Python version and OS
- Complete error message and stack trace  
- Steps to reproduce the problem
- Expected vs actual behavior

### **ğŸ™ Acknowledgments**

- **Hugging Face**: For transformer models and libraries
- **FastAPI**: For the excellent web framework
- **Prometheus & Grafana**: For monitoring and observability
- **FAISS**: For efficient vector similarity search
- **OpenAI/EleutherAI**: For foundation language models

---

## ğŸ‰ **Ready to Transform Your IT Support?**

OpsAI is production-ready and has been tested with real-world IT scenarios. Start with the sample data, then gradually add your organization's historical tickets to improve accuracy.

**Get started in 5 minutes:**
```bash
git clone https://github.com/pheonix-19/OpsAI.git
cd OpsAI
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
pip install -e .
PYTHONPATH=. uvicorn src.api.main:app --reload
```

